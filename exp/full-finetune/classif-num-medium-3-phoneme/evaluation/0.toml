seed = 0
patience = 16
amp = true
n_epochs = -1
batch_size = 1
epoch_size = 10
seq_len_pred = 512
finetune_mode = "full"

[model]
untie_pos_embeddings = false
untie_value_embeddings = false

[model.tabpfn_config]
nhead = 6
emsize = 192
nlayers = 12
nhid_factor = 4

[model.num_embeddings]
type = "LinearEmbeddings"

[data]
seed = 0
num_policy = "noisy-quantile"
cache = true
path = ":data/classif-num-medium-3-phoneme"
old = true

[optimizer]
type = "AdamW"
lr = 2.320794010302052e-05
weight_decay = 0.0
